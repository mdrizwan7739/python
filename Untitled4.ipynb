{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNldwb1rTU7fEjPVBU6RCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdrizwan7739/python/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Amazon Scraping - Sheet1.csv\")\n",
        "links = []\n",
        "for row in df.index:\n",
        "    country = df['country'][row]\n",
        "    asin = df['Asin'][row]\n",
        "    url = f\"https://www.amazon.{country}/dp/{asin}\"\n",
        "    links.append(url)"
      ],
      "metadata": {
        "id": "aG8YrWk_fn_5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def main(URL):\n",
        "    # opening our output file in append mode\n",
        "    File = open(\"out.csv\", \"a\")\n",
        "    File.write(f\"{URL},\")\n",
        "    # specifying user agent, You can use other user agents\n",
        "    # available on the internet\n",
        "    HEADERS = ({'User-Agent':\n",
        "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
        "                                'Accept-Language': 'en-US, en;q=0.5'})\n",
        "\n",
        "    # Making the HTTP Request\n",
        "    webpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "    # Creating the Soup Object containing all data\n",
        "    soup = BeautifulSoup(webpage.content, \"lxml\")\n",
        "\n",
        "    # retrieving product title\n",
        "    try:\n",
        "        # Outer Tag Object\n",
        "        title = soup.find(\"span\",\n",
        "                        attrs={\"id\": 'productTitle'})\n",
        "\n",
        "        # Inner NavigableString Object\n",
        "        title_value = title.string\n",
        "\n",
        "        # Title as a string value\n",
        "        title_string = title_value.strip().replace(',', '')\n",
        "\n",
        "    except AttributeError:\n",
        "        title_string = \"NA\"\n",
        "   \n",
        "    if title_string==\"NA\":\n",
        "        pass\n",
        "    else:\n",
        "        print(\"product Title = \", title_string)\n",
        "\n",
        "    # saving the title in the file\n",
        "        File.write(f\"{title_string},\")\n",
        "    # retrieving price\n",
        "        try:\n",
        "            price = soup.find(\n",
        "            \"span\", attrs={'id': 'priceblock_ourprice'}).string.strip().replace(',', '')\n",
        "        # we are omitting unnecessary spaces\n",
        "        # and commas form our string\n",
        "        except AttributeError:\n",
        "            price = \"NA\"\n",
        "            print(\"Products_price = \", price)\n",
        "     # saving\n",
        "            File.write(f\"{price},\")\n",
        "      \n",
        " # retrieving product rating\n",
        "        try:\n",
        "           rating = soup.find(\"i\", attrs={\n",
        "                        'class': 'a-icon a-icon-star a-star-4-5'}).string.strip().replace(',', '')\n",
        "\n",
        "        except AttributeError:\n",
        "\n",
        "            try:\n",
        "                rating = soup.find(\n",
        "                \"span\", attrs={'class': 'a-icon-alt'}).string.strip().replace(',', '')\n",
        "            except:\n",
        "                rating = \"NA\"\n",
        "                print(\"Overall rating = \", rating)\n",
        "\n",
        "                File.write(f\"{rating},\")\n",
        "\n",
        "        try:\n",
        "            review_count = soup.find(\n",
        "            \"span\", attrs={'id': 'acrCustomerReviewText'}).string.strip().replace(',', '')\n",
        "\n",
        "        except AttributeError:\n",
        "            review_count = \"NA\"\n",
        "            print(\"Total reviews = \", review_count)\n",
        "            File.write(f\"{review_count},\")\n",
        "\n",
        "       # print availablility status\n",
        "        try:\n",
        "            available = soup.find(\"div\", attrs={'id': 'availability'})\n",
        "            available = available.find(\"span\").string.strip().replace(',', '')\n",
        "\n",
        "        except AttributeError:\n",
        "            available = \"NA\"\n",
        "            print(\"Availability = \", available)\n",
        "\n",
        "    # saving the availability and closing the line\n",
        "            File.write(f\"{available},\\n\")\n",
        "\n",
        "    # closing the file\n",
        "        File.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "# opening our url file to access URLs\n",
        "#     file = open(\"url.txt\", \"r\")\n",
        "\n",
        "    # iterating over the urls\n",
        "    for link in links:\n",
        "        main(link)\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiN2PQ0k5g8S",
        "outputId": "c0914742-a0f1-41e0-c8d6-2d12fd1c40b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product Title =  2 leichte Divertimenti für Violine (Oboe) Cello (Fagott) und Klavier - Es-dur KV 252 (240a) und B-dur KV 240 - Bearbeitung (EB 3810)\n",
            "Products_price =  NA\n",
            "Total reviews =  NA\n",
            "product Title =  Chaconne aus der Partita II d-moll BWV 1004 Bearbeitung für Cembalo (EB 6594)\n",
            "Products_price =  NA\n",
            "Total reviews =  NA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1=[]\n",
        "# importing libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def main(URL):\n",
        "    # opening our output file in append mode\n",
        "    File = open(\"out.csv\", \"a\")\n",
        "    File.write(f\"{URL},\")\n",
        "    # specifying user agent, You can use other user agents\n",
        "    # available on the internet\n",
        "    HEADERS = ({'User-Agent':\n",
        "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
        "                                'Accept-Language': 'en-US, en;q=0.5'})\n",
        "\n",
        "    # Making the HTTP Request\n",
        "    webpage = requests.get(URL, headers=HEADERS)\n",
        "\n",
        "    # Creating the Soup Object containing all data\n",
        "    soup = BeautifulSoup(webpage.content, \"lxml\")\n",
        "\n",
        "    # retrieving product title\n",
        "    try:\n",
        "        # Outer Tag Object\n",
        "        title = soup.find(\"span\",\n",
        "                        attrs={\"id\": 'productTitle'})\n",
        "\n",
        "        # Inner NavigableString Object\n",
        "        title_value = title.string\n",
        "\n",
        "        # Title as a string value\n",
        "        title_string = title_value.strip().replace(',', '')\n",
        "\n",
        "    except AttributeError:\n",
        "        title_string = \"NA\"\n",
        "   \n",
        "    if title_string==\"NA\":\n",
        "        pass\n",
        "    else:\n",
        "       # print(\"product Title = \", title_string)\n",
        "         list1.append( title_string)\n",
        "    # saving the title in the file\n",
        "         File.write(f\"{title_string},\")\n",
        "    # retrieving price\n",
        "         try:\n",
        "            price = soup.find(\n",
        "            \"span\", attrs={'id': 'priceblock_ourprice'}).string.strip().replace(',', '')\n",
        "        # we are omitting unnecessary spaces\n",
        "        # and commas form our string\n",
        "         except AttributeError:\n",
        "            price = \"NA\"\n",
        "            #print(\"Products_price = \", price)\n",
        "            list1.append( price)\n",
        "     # saving\n",
        "            File.write(f\"{price},\")\n",
        "      \n",
        " # retrieving product rating\n",
        "            try:\n",
        "                rating = soup.find(\"i\", attrs={\n",
        "                        'class': 'a-icon a-icon-star a-star-4-5'}).string.strip().replace(',', '')\n",
        "\n",
        "            except AttributeError:\n",
        "\n",
        "                try:\n",
        "                    rating = soup.find(\n",
        "                      \"span\", attrs={'class': 'a-icon-alt'}).string.strip().replace(',', '')\n",
        "                except:\n",
        "                    rating = \"NA\"\n",
        "                #print(\"Overall rating = \", rating)\n",
        "                    list1.append( rating)\n",
        "\n",
        "                    File.write(f\"{rating},\")\n",
        "\n",
        "            try:\n",
        "                review_count = soup.find(\n",
        "                     \"span\", attrs={'id': 'acrCustomerReviewText'}).string.strip().replace(',', '')\n",
        "\n",
        "            except AttributeError:\n",
        "                review_count = \"NA\"\n",
        "                #print(\"Total reviews = \", review_count)\n",
        "                list1.append( review_count)\n",
        "                File.write(f\"{review_count},\")\n",
        "\n",
        "       # print availablility status\n",
        "           # try:\n",
        "               # available = soup.find(\"div\", attrs={'id': 'availability'})\n",
        "               # available = available.find(\"span\").string.strip().replace(',', '')\n",
        "\n",
        "           # except AttributeError:\n",
        "            #    available = \"NA\"\n",
        "             #   print(\"Availability = \", available)\n",
        "\n",
        "    # saving the availability and closing the line\n",
        "               # File.write(f\"{available},\\n\")\n",
        "\n",
        "    # closing the file\n",
        "                File.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "# opening our url file to access URLs\n",
        "#     file = open(\"url.txt\", \"r\")\n",
        "\n",
        "    # iterating over the urls\n",
        "    for link in links:\n",
        "        main(link)\n",
        "#print(list1)   \n",
        "ss=json.dumps(list1)     \n",
        "print(ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSTeN-Ri5hJi",
        "outputId": "47126315-36d6-4c8a-fe84-5e4311e9f84d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Arien(2) (grand macabre) 2e akte\", \"NA\", \"NA\", \"Fantasie c piano\", \"NA\", \"NA\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYivucn55hK7",
        "outputId": "bcc13ceb-3666-4199-ebff-0afd39ed188d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(list1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uflcSNfx5hP8",
        "outputId": "502384c8-9a88-4524-b9de-0127e09a16f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1cwZfp3c5hgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZEgJTlON5hin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}